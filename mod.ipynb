{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a1c740-5f96-42b7-ad7a-b0305df06b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9a191-f8de-4673-a6b0-4a52bb7ac2a2",
   "metadata": {},
   "source": [
    "### Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811fb374-01fe-445e-8798-b1b1e5c0b234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JurisType</th>\n",
       "      <th>JurisTypeName</th>\n",
       "      <th>State</th>\n",
       "      <th>Classification Number</th>\n",
       "      <th>Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "      <th>Passage Date</th>\n",
       "      <th>Category Types</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 1-21-22 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Order Granting a Thames Street Extension Licen...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/95133...</td>\n",
       "      <td>2021-07-19 00:00:00</td>\n",
       "      <td>Infrastructure</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 2-21-22 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Order Accepting the Public Art Committee Fisca...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/220d1...</td>\n",
       "      <td>2021-07-19 00:00:00</td>\n",
       "      <td>Infrastructure</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 3-21-22 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Order Granting Municipal Officers’ Approval of...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/84fbd...</td>\n",
       "      <td>2021-07-19 00:00:00</td>\n",
       "      <td>Safety</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 4-21-22 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Order Granting Municipal Officers’ Approval of...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/590d7...</td>\n",
       "      <td>2021-07-19 00:00:00</td>\n",
       "      <td>Zoning</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 5-21-22 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Order Granting Municipal Officers’ Approval of...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/167ff...</td>\n",
       "      <td>2021-07-19 00:00:00</td>\n",
       "      <td>Safety</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 146-23-24 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Granting municipal officers’ approval of Rocke...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/b9b60...</td>\n",
       "      <td>3/18/2024</td>\n",
       "      <td>Community</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 147-23-24 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Granting municipal officers’ approval of Anoth...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/9317f...</td>\n",
       "      <td>3/18/2024</td>\n",
       "      <td>Community</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 148-23-24 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Granting municipal officers’ approval of 15 Ex...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/2125b...</td>\n",
       "      <td>3/18/2024</td>\n",
       "      <td>Community</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 149-23-24 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Accepting and adopting the 2024 Jill C. Duson ...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/46a3f...</td>\n",
       "      <td>3/18/2024</td>\n",
       "      <td>Housing</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Maine</td>\n",
       "      <td>Order 150-23-24 (PDF)</td>\n",
       "      <td>Order</td>\n",
       "      <td>Approving the 2024 Affordable Housing Developm...</td>\n",
       "      <td>https://content.civicplus.com/api/assets/6efa1...</td>\n",
       "      <td>3/18/2024</td>\n",
       "      <td>Housing</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    JurisType JurisTypeName  State Classification Number    Type  \\\n",
       "0        CITY      Portland  Maine    Order 1-21-22 (PDF)  Order   \n",
       "1        CITY      Portland  Maine    Order 2-21-22 (PDF)  Order   \n",
       "2        CITY      Portland  Maine    Order 3-21-22 (PDF)  Order   \n",
       "3        CITY      Portland  Maine    Order 4-21-22 (PDF)  Order   \n",
       "4        CITY      Portland  Maine    Order 5-21-22 (PDF)  Order   \n",
       "..        ...           ...    ...                    ...    ...   \n",
       "531      CITY      Portland  Maine  Order 146-23-24 (PDF)  Order   \n",
       "532      CITY      Portland  Maine  Order 147-23-24 (PDF)  Order   \n",
       "533      CITY      Portland  Maine  Order 148-23-24 (PDF)  Order   \n",
       "534      CITY      Portland  Maine  Order 149-23-24 (PDF)  Order   \n",
       "535      CITY      Portland  Maine  Order 150-23-24 (PDF)  Order   \n",
       "\n",
       "                                          Description   \\\n",
       "0    Order Granting a Thames Street Extension Licen...   \n",
       "1    Order Accepting the Public Art Committee Fisca...   \n",
       "2    Order Granting Municipal Officers’ Approval of...   \n",
       "3    Order Granting Municipal Officers’ Approval of...   \n",
       "4    Order Granting Municipal Officers’ Approval of...   \n",
       "..                                                 ...   \n",
       "531  Granting municipal officers’ approval of Rocke...   \n",
       "532  Granting municipal officers’ approval of Anoth...   \n",
       "533  Granting municipal officers’ approval of 15 Ex...   \n",
       "534  Accepting and adopting the 2024 Jill C. Duson ...   \n",
       "535  Approving the 2024 Affordable Housing Developm...   \n",
       "\n",
       "                                                  Link         Passage Date  \\\n",
       "0    https://content.civicplus.com/api/assets/95133...  2021-07-19 00:00:00   \n",
       "1    https://content.civicplus.com/api/assets/220d1...  2021-07-19 00:00:00   \n",
       "2    https://content.civicplus.com/api/assets/84fbd...  2021-07-19 00:00:00   \n",
       "3    https://content.civicplus.com/api/assets/590d7...  2021-07-19 00:00:00   \n",
       "4    https://content.civicplus.com/api/assets/167ff...  2021-07-19 00:00:00   \n",
       "..                                                 ...                  ...   \n",
       "531  https://content.civicplus.com/api/assets/b9b60...            3/18/2024   \n",
       "532  https://content.civicplus.com/api/assets/9317f...            3/18/2024   \n",
       "533  https://content.civicplus.com/api/assets/2125b...            3/18/2024   \n",
       "534  https://content.civicplus.com/api/assets/46a3f...            3/18/2024   \n",
       "535  https://content.civicplus.com/api/assets/6efa1...            3/18/2024   \n",
       "\n",
       "     Category Types Country  \n",
       "0    Infrastructure     USA  \n",
       "1    Infrastructure     USA  \n",
       "2            Safety     USA  \n",
       "3            Zoning     USA  \n",
       "4            Safety     USA  \n",
       "..              ...     ...  \n",
       "531       Community     USA  \n",
       "532       Community     USA  \n",
       "533       Community     USA  \n",
       "534         Housing     USA  \n",
       "535         Housing     USA  \n",
       "\n",
       "[536 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel(\"Orders.xlsx\")\n",
    "df2 = pd.read_excel(\"Bill.xlsx\")\n",
    "column_names_df1 = list(df1.columns)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e75ac00-2be2-4110-b59d-912f1e51b09e",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a55f18-b398-4512-9504-f70d29e26d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JurisType',\n",
       " 'JurisTypeName',\n",
       " 'State',\n",
       " 'Classification Number ',\n",
       " 'Type',\n",
       " 'Description ',\n",
       " 'Link',\n",
       " 'Passage Date',\n",
       " 'Category Types',\n",
       " 'Country']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940fb5d1-2901-4134-b9ae-306aae076196",
   "metadata": {},
   "source": [
    "### Extracting address from df1 --- description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61cdd3a-17c2-4aab-af23-d810af1ee652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_address(text):\n",
    "    # Define a regex pattern for an address\n",
    "    #print(text)\n",
    "    regexp = \"[0-9]{1,3} .+ (?:Street|St|St.|Avenue|Ave|Boulevard|Blvd|Road|Rd|Lane|Ln|Drive|Dr|Court|Ct|Square|Sq|Trail|Trl|Parkway|Pkwy|Circle|Cir)\"\n",
    "    \n",
    "    address = re.findall(regexp, text)\n",
    "    #print(address)\n",
    "    if (len(address) > 0):\n",
    "        address = address[0]\n",
    "    else:\n",
    "        address = \"\"\n",
    "\n",
    "    return address\n",
    "\n",
    "df1['Address_Extract'] = df1[column_names_df1[2]].apply(extract_address)\n",
    "df1.to_excel(\"address_extract.xlsx\")\n",
    "#df1[column_names_df1[2]][2]\n",
    "#extract_address(df1[column_names_df1[2]][2])\n",
    "#print(extract_address('Order Granting Municipal Officers’ Approval of On the Rocks Cocktail Cruises LLC, dba On the Rocks Cocktail Cruises. Application for a Class I FSE at 68 Commercial Street. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375aeb47-66cd-497e-a652-87d0e3070fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['68 Commercial Street']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = 'Order Granting Municipal Officers’ Approval of On the Rocks Cocktail Cruises LLC, dba On the Rocks Cocktail Cruises. Application for a Class I FSE at 68 Commercial Street. '\n",
    "regexp = \"[0-9]{1,3} .+ (?:Street|St|Avenue|Ave|Boulevard|Blvd|Road|Rd|Lane|Ln|Drive|Dr|Court|Ct|Square|Sq|Trail|Trl|Parkway|Pkwy|Circle|Cir)\"\n",
    "address = re.findall(regexp, txt)\n",
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ec37019-0a60-4306-837b-d8cfb7b83597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Maine\n",
       "1      Maine\n",
       "2      Maine\n",
       "3      Maine\n",
       "4      Maine\n",
       "       ...  \n",
       "531    Maine\n",
       "532    Maine\n",
       "533    Maine\n",
       "534    Maine\n",
       "535    Maine\n",
       "Name: State, Length: 536, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[column_names_df1[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1addac1-e75a-4608-a77c-2ede21260832",
   "metadata": {},
   "source": [
    "### tokenize description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083dd1c5-9804-4241-913a-0c0b631a7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760239e2-b80e-475f-8957-d11986669485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text) #remove digits\n",
    "    words = word_tokenize(text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069e347f-cb39-49a2-ade4-896a51786bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[order, granting, thames, street, extension, l...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[order, accepting, public, art, committee, fis...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[order, granting, municipal, officers, approva...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[order, granting, municipal, officers, approva...</td>\n",
       "      <td>zoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[order, granting, municipal, officers, approva...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>[granting, municipal, officers, approval, rock...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>[granting, municipal, officers, approval, anot...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>[granting, municipal, officers, approval, exch...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>[accepting, adopting, jill, c, duson, housing,...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>[approving, affordable, housing, development, ...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description           Class\n",
       "0    [order, granting, thames, street, extension, l...  infrastructure\n",
       "1    [order, accepting, public, art, committee, fis...  infrastructure\n",
       "2    [order, granting, municipal, officers, approva...          safety\n",
       "3    [order, granting, municipal, officers, approva...          zoning\n",
       "4    [order, granting, municipal, officers, approva...          safety\n",
       "..                                                 ...             ...\n",
       "531  [granting, municipal, officers, approval, rock...       community\n",
       "532  [granting, municipal, officers, approval, anot...       community\n",
       "533  [granting, municipal, officers, approval, exch...       community\n",
       "534  [accepting, adopting, jill, c, duson, housing,...         housing\n",
       "535  [approving, affordable, housing, development, ...         housing\n",
       "\n",
       "[536 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.DataFrame({\n",
    "    'Description' : df1['Description '].replace(to_replace=r'[^\\w\\s]', value='', regex=True).apply(tokenize), \n",
    "    'Class' : df1['Category Types'].str.lower()\n",
    "})\n",
    "base_df2 = pd.DataFrame({\n",
    "    'Description' : df2['Description '].replace(to_replace=r'[^\\w\\s]', value='', regex=True).apply(tokenize), \n",
    "})\n",
    "#remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "base_df['Description'] = base_df['Description'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a059fd21-32ce-4910-a69b-ca5617afdc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[act, expand, health, insurance, options, chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, amend, mining, excise, tax, laws]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[act, protect, victims, domestic, abuse, viole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[act, require, health, insurance, coverage, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[act, regarding, recommendations, changing, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>[act, amend, laws, governing, invasive, aquati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>[act, implement, recommendations, probate, tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>[act, clarify, boundary, waldo, knox, counties...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>[act, update, reimbursement, travelrelated, ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>[act, establish, winter, energy, relief, payme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description\n",
       "0    [act, expand, health, insurance, options, chil...\n",
       "1              [act, amend, mining, excise, tax, laws]\n",
       "2    [act, protect, victims, domestic, abuse, viole...\n",
       "3    [act, require, health, insurance, coverage, bi...\n",
       "4    [act, regarding, recommendations, changing, pl...\n",
       "..                                                 ...\n",
       "923  [act, amend, laws, governing, invasive, aquati...\n",
       "924  [act, implement, recommendations, probate, tru...\n",
       "925  [act, clarify, boundary, waldo, knox, counties...\n",
       "926  [act, update, reimbursement, travelrelated, ex...\n",
       "927  [act, establish, winter, energy, relief, payme...\n",
       "\n",
       "[928 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df2['Description'] = base_df2['Description'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "base_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d22f30-f41d-4c07-bdd2-b1206ef0d637",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2552fd6e-228c-492d-aea1-6e33a5ced1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e0ab52-1ef6-4078-9645-10eea17af557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[order, grant, thame, street, extens, licens, ...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[order, accept, public, art, committe, fiscal,...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[order, grant, municip, offic, approv, rock, c...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[order, grant, municip, offic, approv, hi, fid...</td>\n",
       "      <td>zoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[order, grant, municip, offic, approv, tokyo, ...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>[grant, municip, offic, approv, rocket, skate,...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>[grant, municip, offic, approv, anoth, round, ...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>[grant, municip, offic, approv, exchang, llc, ...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>[accept, adopt, jill, c, duson, hous, trust, f...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>[approv, afford, hous, develop, tax, increment...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description           Class\n",
       "0    [order, grant, thame, street, extens, licens, ...  infrastructure\n",
       "1    [order, accept, public, art, committe, fiscal,...  infrastructure\n",
       "2    [order, grant, municip, offic, approv, rock, c...          safety\n",
       "3    [order, grant, municip, offic, approv, hi, fid...          zoning\n",
       "4    [order, grant, municip, offic, approv, tokyo, ...          safety\n",
       "..                                                 ...             ...\n",
       "531  [grant, municip, offic, approv, rocket, skate,...       community\n",
       "532  [grant, municip, offic, approv, anoth, round, ...       community\n",
       "533  [grant, municip, offic, approv, exchang, llc, ...       community\n",
       "534  [accept, adopt, jill, c, duson, hous, trust, f...         housing\n",
       "535  [approv, afford, hous, develop, tax, increment...         housing\n",
       "\n",
       "[536 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(words):\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "base_df['Description'] = base_df['Description'].apply(stem_words)\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e867573-ace0-4233-a8a4-66207bee9f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[act, expand, health, insur, option, child, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, amend, mine, excis, tax, law]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[act, protect, victim, domest, abus, violenc, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[act, requir, health, insur, coverag, biomark,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[act, regard, recommend, chang, place, name, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>[act, amend, law, govern, invas, aquat, plant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>[act, implement, recommend, probat, trust, law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>[act, clarifi, boundari, waldo, knox, counti, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>[act, updat, reimburs, travelrel, expens, incu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>[act, establish, winter, energi, relief, payme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description\n",
       "0    [act, expand, health, insur, option, child, ca...\n",
       "1                  [act, amend, mine, excis, tax, law]\n",
       "2    [act, protect, victim, domest, abus, violenc, ...\n",
       "3    [act, requir, health, insur, coverag, biomark,...\n",
       "4    [act, regard, recommend, chang, place, name, s...\n",
       "..                                                 ...\n",
       "923     [act, amend, law, govern, invas, aquat, plant]\n",
       "924  [act, implement, recommend, probat, trust, law...\n",
       "925  [act, clarifi, boundari, waldo, knox, counti, ...\n",
       "926  [act, updat, reimburs, travelrel, expens, incu...\n",
       "927  [act, establish, winter, energi, relief, payme...\n",
       "\n",
       "[928 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df2['Description'] = base_df2['Description'].apply(stem_words)\n",
    "base_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1f42b-b513-471b-bc39-67d0673e35aa",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39741a01-b5c1-4b8a-8ba3-9dd867f44cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f42b28-2a3b-40c4-93fb-d27f38a2e276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[order, grant, thame, street, extens, licens, ...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[order, accept, public, art, committe, fiscal,...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[order, grant, municip, offic, approv, rock, c...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[order, grant, municip, offic, approv, hi, fid...</td>\n",
       "      <td>zoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[order, grant, municip, offic, approv, tokyo, ...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>[grant, municip, offic, approv, rocket, skate,...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>[grant, municip, offic, approv, anoth, round, ...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>[grant, municip, offic, approv, exchang, llc, ...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>[accept, adopt, jill, c, duson, hous, trust, f...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>[approv, afford, hous, develop, tax, increment...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description           Class\n",
       "0    [order, grant, thame, street, extens, licens, ...  infrastructure\n",
       "1    [order, accept, public, art, committe, fiscal,...  infrastructure\n",
       "2    [order, grant, municip, offic, approv, rock, c...          safety\n",
       "3    [order, grant, municip, offic, approv, hi, fid...          zoning\n",
       "4    [order, grant, municip, offic, approv, tokyo, ...          safety\n",
       "..                                                 ...             ...\n",
       "531  [grant, municip, offic, approv, rocket, skate,...       community\n",
       "532  [grant, municip, offic, approv, anoth, round, ...       community\n",
       "533  [grant, municip, offic, approv, exchang, llc, ...       community\n",
       "534  [accept, adopt, jill, c, duson, hous, trust, f...         housing\n",
       "535  [approv, afford, hous, develop, tax, increment...         housing\n",
       "\n",
       "[536 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    def get_wordnet_pos(word):\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "    lemmas = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    return lemmas\n",
    "\n",
    "base_df['Description'] = base_df['Description'].apply(lemmatize_tokens)\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ae26e3-7d6a-4242-b81c-5252248ef3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[act, expand, health, insur, option, child, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, amend, mine, excis, tax, law]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[act, protect, victim, domest, abus, violenc, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[act, requir, health, insur, coverag, biomark,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[act, regard, recommend, chang, place, name, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>[act, amend, law, govern, invas, aquat, plant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>[act, implement, recommend, probat, trust, law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>[act, clarifi, boundari, waldo, knox, counti, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>[act, updat, reimburs, travelrel, expens, incu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>[act, establish, winter, energi, relief, payme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description\n",
       "0    [act, expand, health, insur, option, child, ca...\n",
       "1                  [act, amend, mine, excis, tax, law]\n",
       "2    [act, protect, victim, domest, abus, violenc, ...\n",
       "3    [act, requir, health, insur, coverag, biomark,...\n",
       "4    [act, regard, recommend, chang, place, name, s...\n",
       "..                                                 ...\n",
       "923     [act, amend, law, govern, invas, aquat, plant]\n",
       "924  [act, implement, recommend, probat, trust, law...\n",
       "925  [act, clarifi, boundari, waldo, knox, counti, ...\n",
       "926  [act, updat, reimburs, travelrel, expens, incu...\n",
       "927  [act, establish, winter, energi, relief, payme...\n",
       "\n",
       "[928 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df2['Description'] = base_df2['Description'].apply(lemmatize_tokens)\n",
    "base_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3896329e-2de7-4803-a86c-acd8bbd1bf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "infrastructure             112\n",
       "community                   83\n",
       "governance                  64\n",
       "safety                      62\n",
       "housing                     35\n",
       "zoning                      30\n",
       "education                   21\n",
       "environmental               20\n",
       "finance                     17\n",
       "public safety               16\n",
       "human resources             11\n",
       "legislation                 11\n",
       "administration              10\n",
       "arts & culture               7\n",
       "legal                        6\n",
       "employment                   5\n",
       "fiscal                       4\n",
       "public services              4\n",
       "transportation               4\n",
       "health & human services      3\n",
       "real estate                  3\n",
       "social services              3\n",
       "community services           2\n",
       "energy                       2\n",
       "environment                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a177d9-27bf-4c10-ab3c-a39f1a920d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7dbf94d-ac16-4852-a6d6-90e1c7beace2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[order, grant, thame, street, extens, licens, ...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[order, accept, public, art, committe, fiscal,...</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[order, grant, municip, offic, approv, rock, c...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[order, grant, municip, offic, approv, hi, fid...</td>\n",
       "      <td>zoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[order, grant, municip, offic, approv, tokyo, ...</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>[grant, municip, offic, approv, rocket, skate,...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>[grant, municip, offic, approv, anoth, round, ...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>[grant, municip, offic, approv, exchang, llc, ...</td>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>[accept, adopt, jill, c, duson, hous, trust, f...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>[approv, afford, hous, develop, tax, increment...</td>\n",
       "      <td>housing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Description           Class\n",
       "0    [order, grant, thame, street, extens, licens, ...  infrastructure\n",
       "1    [order, accept, public, art, committe, fiscal,...  infrastructure\n",
       "2    [order, grant, municip, offic, approv, rock, c...          safety\n",
       "3    [order, grant, municip, offic, approv, hi, fid...          zoning\n",
       "4    [order, grant, municip, offic, approv, tokyo, ...          safety\n",
       "..                                                 ...             ...\n",
       "531  [grant, municip, offic, approv, rocket, skate,...       community\n",
       "532  [grant, municip, offic, approv, anoth, round, ...       community\n",
       "533  [grant, municip, offic, approv, exchang, llc, ...       community\n",
       "534  [accept, adopt, jill, c, duson, hous, trust, f...         housing\n",
       "535  [approv, afford, hous, develop, tax, increment...         housing\n",
       "\n",
       "[492 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = base_df.groupby('Class').filter(lambda x: len(x) >= 10)\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6d6d4be-2045-4177-b57d-8c5a2b481002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "infrastructure     112\n",
       "community           83\n",
       "governance          64\n",
       "safety              62\n",
       "housing             35\n",
       "zoning              30\n",
       "education           21\n",
       "environmental       20\n",
       "finance             17\n",
       "public safety       16\n",
       "human resources     11\n",
       "legislation         11\n",
       "administration      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e2303-726d-4c7a-9f84-be5ef89bce91",
   "metadata": {},
   "source": [
    "### First round implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcb565d1-6a6c-4ffe-aece-07a0ec3a7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(base_df['Description'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Encode the class labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(base_df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa565169-6117-4bba-b566-2aee5dabe6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X, y = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72f42e7d-e785-4a22-8c58-2cac6b35700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd4b2f-d91e-47d2-8125-8024b2af8f3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "102d0103-f110-46be-8ce7-feae33b6751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47f2a698-ed2a-456d-b1eb-d775658b333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842105263157895"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d341e-c218-4f68-a3e3-0e052b9e2d0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "789d58a9-dd23-4cdc-b265-18badf948ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "178c6f17-53aa-48c9-92a8-3642894d27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5344b502-882d-42d8-a14c-3ad52ed9ff6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986270022883295"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717121b-3d5e-415d-99b4-e5bfda753b40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b88def85-0e5e-47eb-b00a-f963d32bdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d6f0f42-16ae-44df-a4b8-1c83dec302b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63109e82-1287-4919-a778-edee530a9938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7665903890160183"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948766d5-3797-4bb2-a03b-043959e1b22f",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0e46efa-cc5f-405a-a088-73f3363223b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6399de81-5b0e-46d1-a5f6-d3b19c5d14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e21a0916-bb3d-4977-95d2-482783c461f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7780320366132724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f50d64-2774-40c6-9eef-82fc214963d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Neural Network(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9de1f7f3-1963-4f7b-9687-e97a7c5c83aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09ecfba3-de22-410b-b3db-722d242f1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lst = [\"BinaryCrossentropy\", \"BinaryFocalCrossentropy\", \n",
    "            \"CTC\", \"CategoricalCrossentropy\", \"CategoricalFocalCrossentropy\", \n",
    "            \"CategoricalHinge\", \"CosineSimilarity\", \"Dice\", \"Hinge\", \"Huber\", \n",
    "            \"KLDivergence\", \"Loss\", \"MeanAbsoluteError\", \"MeanAbsolutePercentageError\", \n",
    "            \"MeanSquaredError\", \"MeanSquaredLogarithmicError\", \"Poisson\", \"Reduction\", \n",
    "            \"SparseCategoricalCrossentropy\", \"SquaredHinge\", \"Tversky\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fea578ba-4d87-45d5-b6ff-8d5860148c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 3s - 482ms/step - accuracy: 0.1570 - loss: 0.1080 - val_accuracy: 0.1824 - val_loss: 0.1037\n",
      "Epoch 2/5\n",
      "6/6 - 0s - 56ms/step - accuracy: 0.1628 - loss: 0.0730 - val_accuracy: 0.1824 - val_loss: 0.0455\n",
      "Epoch 3/5\n",
      "6/6 - 0s - 54ms/step - accuracy: 0.1628 - loss: 0.0432 - val_accuracy: 0.1824 - val_loss: 0.0412\n",
      "Epoch 4/5\n",
      "6/6 - 0s - 53ms/step - accuracy: 0.1628 - loss: 0.0411 - val_accuracy: 0.1824 - val_loss: 0.0407\n",
      "Epoch 5/5\n",
      "6/6 - 0s - 53ms/step - accuracy: 0.1628 - loss: 0.0408 - val_accuracy: 0.1824 - val_loss: 0.0406\n",
      "Accuracy: 0.18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(base_df['Description'])\n",
    "X = tokenizer.texts_to_sequences(base_df['Description'])\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(base_df['Class'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='CategoricalHinge', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e8a16-e912-4cda-8f93-75675d9a5489",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e48050b5-7c01-4033-b03b-ba59606f9a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [4, 3, 5, 11, 8, 2, 11, 8, 1, 8, 2, 12, 8, 8, 8, 5, 8, 5, 8, 3, 2, 1, 1, 4, 8, 1, 8, 1, 8, 5, 11, 1, 8, 8, 8, 8, 3, 4, 8, 1, 8, 1, 1, 11, 1, 1, 8, 11, 8, 8, 8, 11, 1, 8, 8, 8, 11, 8, 6, 5, 1, 8, 11, 3, 8, 5, 8, 8, 8, 8, 1, 8, 1, 3, 5, 5, 5, 8, 11, 1, 12, 8, 8, 10, 8, 8, 2, 3, 1, 1, 8, 11, 1, 8, 8, 8, 1, 3, 8, 0, 12, 8, 1, 1, 1, 1, 8, 10, 1, 8, 9, 8, 11, 1, 9, 1, 1, 12, 8, 8, 8, 10, 11, 8, 11, 10, 4, 2, 8, 11, 8, 1, 8, 8, 8, 8, 1, 8, 4, 6, 9, 0, 1, 8, 8, 12, 8, 8]\n",
      "Actual labels: [ 8 11  5 10 11  2 11  8  3  6  2  5 11 11  5 11  8  0 12  1  4  0  1  4\n",
      "  8  1  5 11  1  5  8  6  3  5 11  4  8  8  8  1  2  8  8 11 11  1  8  5\n",
      " 11  1  1 11  1 11  1  8  1  1 11 12  8  6  1  8  6 12 12  5  5  3  1  0\n",
      "  5  6  8  8  5  1  2  9 12  8  6  5  5  6  1  8 12  6 11  2  1 12  2  6\n",
      " 11  5  9  8 11  1  7  1  3  5  1  1  1  8  9  2 11  3  9 10  5  6  2  8\n",
      "  2  8 11 11 10  8  4  2  8  5  8  3  1  8  8  5 11  1  4 11  9  1  1 12\n",
      "  8 11  8  1]\n",
      "Accuracy: 0.2905405405405405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "k = 2  # Number of neighbors\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='cosine')\n",
    "nn.fit(X_train)  # NearestNeighbors requires dense input if using cosine\n",
    "\n",
    "# Finding the k-nearest neighbors for each point in the test set\n",
    "distances, indices = nn.kneighbors(X_test)\n",
    "\n",
    "# Voting logic to classify based on the nearest neighbors\n",
    "y_pred = []\n",
    "for index_array in indices:\n",
    "    neighbor_labels = [y_train[idx] for idx in index_array]\n",
    "    # Get the most common class label among the nearest neighbors\n",
    "    most_common = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    y_pred.append(most_common)\n",
    "\n",
    "# Compare the predictions with the actual labels\n",
    "print(\"Predicted labels:\", y_pred)\n",
    "print(\"Actual labels:\", y_test)\n",
    "#calculate accuracy\n",
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == y_test[i]):\n",
    "        count += 1\n",
    "print (\"Accuracy:\", count / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d81a8-1363-4c34-999f-6dd287ba9377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b93db-06fc-461f-9b2b-9980410211a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8664dc3-d99d-4f29-9382-f88839437e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eaadfb-9737-4454-ba96-105347d66d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d6941-c38e-4a24-89f4-00c3861c2714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6246bfde-87c9-4f1c-aeda-509d1eb1498f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2ca1890-d286-4290-91ce-392c24a8825c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### N gram model -- feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23ad2bb5-517b-4738-a4b4-b1bb27da43f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 2))  \n",
    "X = vectorizer.fit_transform(base_df['Description'].apply(lambda x: ' '.join(x)))\n",
    "# Encode the class labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(base_df['Class'])\n",
    "\n",
    "smote = SMOTE()\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13e1ef95-9b5e-463e-92b4-65ab1f208471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6247139588100686"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc99dffe-7af5-40a3-afab-b6d7c7dd7571",
   "metadata": {},
   "source": [
    "### TF-IDF model -- feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a251e3-c3ce-4be0-8237-0ae63bbc7fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a32ff42f-3059-4948-a8d3-28ac8c84f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(base_df['Description'].apply(lambda x: ' '.join(x)))\n",
    "X_final = vectorizer.fit_transform(base_df2['Description'].apply(lambda x: ' '.join(x)))\n",
    "# Encode the class labels\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(base_df['Class'])\n",
    "\n",
    "smote = SMOTE()\n",
    "X, y = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8090da-1b2e-4d3d-91ad-45095434b1ed",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55c6d07c-5d7f-408c-923f-90a7e4976d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f7caa88-1a78-4371-8f6e-911d388551ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9107551487414187"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3423d8fc-3909-4661-9c7d-84afabaf00e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Logistic Regression parameter adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "781e65c8-c36b-414f-906d-ed2b5d8afacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5921b56e-16ec-4e6d-928c-016034f434ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "E:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Fit grid search\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[0;32m     18\u001b[0m results \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mcv_results_\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[0;32m   1292\u001b[0m     path_func(\n\u001b[0;32m   1293\u001b[0m         X,\n\u001b[0;32m   1294\u001b[0m         y,\n\u001b[0;32m   1295\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[0;32m   1296\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[0;32m   1297\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[0;32m   1298\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   1299\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m   1300\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1301\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[0;32m   1302\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[0;32m   1303\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m   1304\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m   1305\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1306\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m   1307\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[0;32m   1308\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m   1309\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[0;32m   1310\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1311\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1312\u001b[0m     )\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[0;32m   1314\u001b[0m )\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:450\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    446\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    447\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    448\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    449\u001b[0m ]\n\u001b[1;32m--> 450\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[0;32m    451\u001b[0m     func,\n\u001b[0;32m    452\u001b[0m     w0,\n\u001b[0;32m    453\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    454\u001b[0m     jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    455\u001b[0m     args\u001b[38;5;241m=\u001b[39m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[0;32m    456\u001b[0m     options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m\"\u001b[39m: iprint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtol\u001b[39m\u001b[38;5;124m\"\u001b[39m: tol, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_iter},\n\u001b[0;32m    457\u001b[0m )\n\u001b[0;32m    458\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    459\u001b[0m     solver,\n\u001b[0;32m    460\u001b[0m     opt_res,\n\u001b[0;32m    461\u001b[0m     max_iter,\n\u001b[0;32m    462\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    463\u001b[0m )\n\u001b[0;32m    464\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:274\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    271\u001b[0m n_dof \u001b[38;5;241m=\u001b[39m n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_prediction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     weights, intercept, raw_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept_raw(coef, X)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    276\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:165\u001b[0m, in \u001b[0;36mLinearModelLoss.weight_intercept_raw\u001b[1;34m(self, coef, X)\u001b[0m\n\u001b[0;32m    162\u001b[0m     raw_prediction \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m weights \u001b[38;5;241m+\u001b[39m intercept\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# weights has shape (n_classes, n_dof)\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     raw_prediction \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m weights\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m+\u001b[39m intercept  \u001b[38;5;66;03m# ndarray, likely C-contiguous\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights, intercept, raw_prediction\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\sparse\\_base.py:624\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_dispatch(other)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\sparse\\_base.py:526\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_vector(other\u001b[38;5;241m.\u001b[39mravel())\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[1;32m--> 526\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_multivector(other)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:501\u001b[0m, in \u001b[0;36m_cs_matrix._mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[0;32m    500\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvecs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 501\u001b[0m fn(M, N, n_vecs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m    502\u001b[0m    other\u001b[38;5;241m.\u001b[39mravel(), result\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'solver': [\"newton-cg\",\"sag\", \"saga\", \"lbfgs\"],  # Suitable for small datasets and binary classification\n",
    "    'penalty': ['l1', 'l2'],  # Trying both L1 and L2 regularization\n",
    "    'C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Setup the grid search with 10-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=10)  # Ensuring each fold is a good representative of the whole\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract results\n",
    "results = grid_search.cv_results_\n",
    "max_accuracy = max(results['mean_test_score'])\n",
    "print(\"Accuracy:\", max_accuracy)\n",
    "print(\"Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86db32-0f70-4fba-a6c3-4b00f10ec887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca3380-2e09-42be-9b8e-0b85e5655db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa03592-e1e2-4b62-bc95-12614373ea9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f652487d-d0cd-4ee0-8986-4f6d838f7470",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcc1a252-e35c-4bca-bf3b-a873fb3673ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f70f36c8-69e6-44b2-af35-cc74528a670e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489702517162472"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94303036-ab44-42d5-b8f2-780df20b8934",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b415d6aa-ccc1-4905-a005-5a7e361664da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(random_state = 42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0304aaf0-edbc-4a3b-8a6d-a019a453cf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061784897025171"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becad31-d806-4a2b-af30-b2988779e3b7",
   "metadata": {},
   "source": [
    "#### parameter adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66e562d3-28f8-4d23-b762-e6de794820f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9382664147378366\n",
      "Parameters: {'gamma': 'scale', 'tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "model = SVC(max_iter = 1000)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'gamma' : ['scale', 'auto'], \n",
    "    'tol' : np.arange(0.00001, 0.001, 0.00001), \n",
    "}\n",
    "\n",
    "# Setup the grid search with 10-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=10)  # Ensuring each fold is a good representative of the whole\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract results\n",
    "results = grid_search.cv_results_\n",
    "max_accuracy = max(results['mean_test_score'])\n",
    "print(\"Accuracy:\", max_accuracy)\n",
    "print(\"Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f9a42-8a69-4bcb-baa7-28c4ebd505ca",
   "metadata": {},
   "source": [
    "#### final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eda5093d-5516-4207-93b0-e9c8e304a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(max_iter = 1000, gamma = \"scale\", tol = 1e-05, random_state = 42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8ea64db-720a-44bc-a1bc-b10b476f2146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061784897025171"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = svm_model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f2785-bad7-4cdd-931f-149a108c16c2",
   "metadata": {},
   "source": [
    "#### underfitting or overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83dcf663-a0a3-42ad-b17a-193a666c4141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842983316977428"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = svm_model.predict(X_train)\n",
    "accuracy = metrics.accuracy_score(y_train, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225919fb-b7a3-44b7-b1dd-a24965b4e7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501239b-2886-47f6-83f6-80dfb3e47a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba5451f0-d884-4399-95aa-e9b9a360a96d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0b19b4f-d341-4aaf-95b9-aaa0218faa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c808ca3b-de26-4650-886f-d5453fb1e8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9016018306636155"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, predicted_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12aef6e-eb17-4db7-a13f-d52d860417ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### parameter adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c30588d-3ea2-40df-89a4-87537ff437b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n"
     ]
    }
   ],
   "source": [
    "n_estimators_lst = []\n",
    "max_depth_lst = []\n",
    "max_leaf_nodes_lst = []\n",
    "accuracy_lst = []\n",
    "count = 1\n",
    "for n in range (100, 201, 20):\n",
    "    for depth in range (2, 20):\n",
    "        for leaf in range (2, 20):\n",
    "            if (count % 10 == 0):\n",
    "                print (count)\n",
    "            count += 1\n",
    "            model = RandomForestClassifier(n_estimators = n, max_depth = depth, max_leaf_nodes = leaf, random_state = 42)\n",
    "            cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "            n_estimators_lst.append(n)\n",
    "            max_depth_lst.append(depth)\n",
    "            max_leaf_nodes_lst.append(leaf)\n",
    "            accuracy_lst.append(np.mean(cv_scores))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0ef4696-f74e-4a77-9692-13c348e2831f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.798838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>0.797473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0.797463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0.795418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0.795413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.614095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.614095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.614095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.614095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>120</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.614095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1944 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_estimators  max_depth  max_leaf_nodes  accuracy\n",
       "1727           200          7              19  0.798838\n",
       "1097           160          8              19  0.797473\n",
       "1079           160          7              19  0.797463\n",
       "1133           160         10              19  0.795418\n",
       "1781           200         10              19  0.795413\n",
       "...            ...        ...             ...       ...\n",
       "414            120          7               2  0.614095\n",
       "396            120          6               2  0.614095\n",
       "378            120          5               2  0.614095\n",
       "360            120          4               2  0.614095\n",
       "468            120         10               2  0.614095\n",
       "\n",
       "[1944 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df = pd.DataFrame({\n",
    "    \"n_estimators\" : n_estimators_lst, \n",
    "    \"max_depth\" : max_depth_lst, \n",
    "    \"max_leaf_nodes\" : max_leaf_nodes_lst, \n",
    "    \"accuracy\" : accuracy_lst\n",
    "})\n",
    "rf_df = rf_df.sort_values(by = [\"accuracy\"], ascending = [False])\n",
    "rf_df.to_csv(\"rf_df.csv\")\n",
    "rf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831d47a-8196-43b2-8262-9342e4f9103e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### overfitting / underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35691829-ede8-40c7-b826-c298cf890934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "696cfa04-b9eb-435c-9754-007e9f4a46e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8361138370951914"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = n, max_depth = depth, max_leaf_nodes = leaf, random_state = 42).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_train)\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5c194d29-ba6c-47cb-b4db-9a0e4deff6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "model = RandomForestClassifier(n_estimators = n, max_depth = depth, max_leaf_nodes = leaf, random_state = 42).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "#accuracy\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "TP = cm[1, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Calculate sensitivity\n",
    "sensitivity = TP / (TP + FN)\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3670f1b-a494-4767-b3c9-a0285ca93a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211431270666036"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "cv_scores = cross_val_score(model, X, y, cv=10)\n",
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b22f51a-e4e7-4a15-a695-626fe41471af",
   "metadata": {},
   "source": [
    "### use final model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8caf4e8f-b3c2-43b0-a445-9e9517a849e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  8,  8,  4,  8,  8,  8,  1,  3,  8,  3, 12,  8,  8,  8,  8,  8,\n",
       "        1,  8,  1,  1,  8, 10,  1,  1,  1, 10,  8,  8,  1,  8,  8, 11,  1,\n",
       "        8, 10,  1, 11,  8, 12,  8,  8,  1,  8,  8,  8,  8, 10,  1,  1,  1,\n",
       "       12,  8, 12,  8,  1,  8,  8,  1,  8,  8,  1, 12,  8,  1, 12,  1,  8,\n",
       "        1,  6,  1,  1, 11,  8,  1,  1,  1,  8,  1,  8,  8,  8,  1,  8,  8,\n",
       "        8,  8,  8, 12,  3, 11,  1,  8,  1,  8,  1, 12,  1,  8,  1, 12,  8,\n",
       "        8,  8,  1,  1,  1,  8,  1,  1,  8,  8,  8,  8,  8,  8,  1,  1,  1,\n",
       "       10,  1,  8,  1,  1,  8,  8,  1,  8,  1,  8,  6,  8,  8, 12,  1,  8,\n",
       "       12,  8,  8,  1,  1, 12, 10,  8,  8,  1,  1, 11,  8,  8,  8,  8,  1,\n",
       "        1,  1,  8,  1,  8,  8,  8,  8,  1,  3, 10,  8,  1,  8,  8,  8,  1,\n",
       "        8,  8,  5,  1,  1,  8,  1,  8,  8,  1,  8,  1,  1,  5,  1,  1,  1,\n",
       "        5,  8,  1,  1,  1,  1,  8,  1,  8,  1,  8, 11,  8,  1,  1,  1,  8,\n",
       "        1,  1,  1,  8, 12,  8,  8,  8,  8, 11,  1,  6,  1,  1, 12,  8,  1,\n",
       "        8,  1, 10,  8,  1, 11,  1,  8,  1,  8,  8,  8,  3,  8,  8,  3,  8,\n",
       "        8,  8,  8,  1,  1,  1,  1,  8, 10,  8,  8,  1,  3,  8,  1,  1,  8,\n",
       "        7,  1,  8,  8,  8,  1,  8,  1,  8,  8,  8,  1, 12,  1, 12,  1,  1,\n",
       "        3,  1,  8,  8,  8,  8,  8,  1,  1, 12,  8,  1,  1,  3,  8, 12,  1,\n",
       "        8,  8,  1, 12,  8,  8,  8,  5,  8,  8,  8, 11,  1,  8, 11, 11,  1,\n",
       "        8,  8,  8,  8,  8,  8,  1, 10,  3,  8,  1,  8,  1,  8,  8,  1,  8,\n",
       "        1,  1,  8,  1,  8,  8,  1,  8, 10,  1,  1,  1,  1,  8,  8, 10,  8,\n",
       "       12, 12,  1,  1,  1,  8,  4,  8,  8,  8, 10,  1,  1,  8,  8,  1,  1,\n",
       "        8,  1, 10,  8,  1,  5,  8,  1,  1,  1,  1, 10,  8,  8,  8,  8,  1,\n",
       "        8,  8,  1,  8,  1,  8,  8,  8,  1,  1,  1,  1,  8,  1,  8,  1, 12,\n",
       "        8,  1,  8,  1,  1,  1,  1,  8,  8,  8,  1,  1,  8,  1, 10,  8,  1,\n",
       "        1,  1, 11,  8,  8,  1,  8,  8,  8,  1,  1,  8, 10,  1,  1,  8,  8,\n",
       "        1,  1, 12,  8,  8,  1,  8, 10, 10,  1,  8, 10, 12,  8,  1,  1,  1,\n",
       "        1,  8,  1,  1,  1,  1,  8,  1,  5,  1,  8,  8,  1,  8,  8,  1,  8,\n",
       "       11,  1,  1,  8,  1,  1,  1,  8,  1,  8,  8,  8,  8,  8,  1,  1,  3,\n",
       "       12,  1,  8,  8,  1,  8,  1,  1,  8,  8,  8, 12,  1, 11,  8,  3,  3,\n",
       "        8,  1,  8,  1,  1,  8,  1,  8,  1,  8, 12,  8,  1,  8, 12,  8,  5,\n",
       "        8,  8,  8,  1,  8, 10,  1,  1,  8,  1,  8,  8,  1,  8,  1, 12,  8,\n",
       "        8,  8,  1,  1,  8,  6,  8,  8,  8,  8,  8,  1,  1,  1,  8,  1,  1,\n",
       "        8,  1,  1,  8, 12,  8, 11, 10,  1,  8, 12, 12,  1,  1,  8,  8,  1,\n",
       "       12,  8,  3,  8,  1,  8,  8,  8,  8,  8,  1, 10,  8,  1,  3,  1,  8,\n",
       "        1, 12,  1,  1,  1,  1,  8,  1,  8,  1,  1,  5,  8,  1,  8,  1,  1,\n",
       "        3,  8,  1,  1,  1, 10,  5,  1,  1,  3,  1,  1,  8,  8,  8,  8,  1,\n",
       "        1,  1,  8,  8,  3,  8, 10, 12,  6,  8,  1,  1,  8, 12,  1,  8,  8,\n",
       "        1,  8,  8,  8,  8,  1,  8,  1,  1,  1,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  1,  8,  8,  8,  8,  1,  1,  8,  8,  8,  8,  1,  8,  8,  1,  1,\n",
       "       11,  1,  5, 12,  8,  1,  8,  1,  3,  8,  1,  1, 10, 10,  8,  1, 12,\n",
       "        1,  8,  8,  1,  8,  6,  8,  3,  1,  1, 11,  1,  8,  1, 11,  1,  1,\n",
       "       12,  1, 10, 12, 12,  8,  1, 12,  2,  8, 10,  8,  8,  8,  8,  1,  1,\n",
       "        8,  1,  1,  1,  8,  1,  8,  8,  8,  1,  1,  8,  1,  8,  8,  8,  8,\n",
       "        8,  8,  1,  8,  8,  1,  1,  1,  8,  8,  8,  1,  8,  8,  8,  8,  1,\n",
       "        8,  5,  8,  1,  1,  1,  8,  8,  8,  1, 10, 12, 12,  8,  8,  1,  1,\n",
       "        8,  8,  1,  8,  8, 12,  8,  8,  1,  1,  8,  8, 11,  6,  8,  8,  8,\n",
       "        6,  8,  1,  1,  8,  1,  1,  3,  8,  1,  1,  1,  8,  8,  1,  1, 10,\n",
       "        8,  8,  1,  1,  8, 12,  1,  1,  8,  8,  1,  1,  0,  1, 10,  1,  5,\n",
       "        1,  8,  1,  8,  1,  8,  1, 12,  8,  8,  8,  1,  1,  8,  8,  1,  8,\n",
       "        1, 11,  1,  1,  1,  1,  8,  8, 12, 10,  8,  1,  1,  8, 12,  8,  1,\n",
       "        1,  8,  8,  1,  8,  8,  1,  1,  1,  1,  1,  1,  8,  1,  1,  1,  1,\n",
       "        3,  3, 12, 10,  8,  8,  8, 12,  1,  1,  8,  6,  8,  8,  1,  1, 12,\n",
       "        1,  8, 12,  1,  8,  8,  1,  8,  1,  1,  1,  8,  8,  1,  1,  8,  8,\n",
       "        1,  8, 12,  1,  8,  8,  1,  1,  8,  8,  1,  8,  8,  8,  8,  1,  1,\n",
       "        1,  8,  8,  1,  8,  8,  8,  1,  1,  8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = classifier.predict(X_final[:,2:1029])\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a968bf3-04e4-4486-8af0-280390e6b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(drop=True, inplace=True)\n",
    "#final_pred.reset_index(drop=True, inplace=True)\n",
    "df2['Category Types'] = list(encoder.inverse_transform(final_pred))\n",
    "df2.to_csv(\"new_df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8a23dd56-8849-49ab-b527-e23e04c15478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bf36aef6-0bbc-45c6-b02f-99059902d726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "       ..\n",
       "923   NaN\n",
       "924   NaN\n",
       "925   NaN\n",
       "926   NaN\n",
       "927   NaN\n",
       "Name: Category Types, Length: 928, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Category Types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4eb867-cd11-480f-8e6a-e790c61831c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d21b7e2f-ed8c-435d-b002-1205673edfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 83)\\t0.009490899976104767\\n  (0, 231)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 347)\\t0.0717112251874176\\n  (0, 62)\\t0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 1001)\\t0.4714018667072575\\n  (0, 424)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 149)\\t0.12681261954079942\\n  (0, 21)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 627)\\t0.12736300042116153\\n  (0, 62)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>(0, 136)\\t0.4251433515438467\\n  (0, 958)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>(0, 186)\\t0.14346710639962854\\n  (0, 597)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>(0, 62)\\t0.03098285517981942\\n  (0, 58)\\t0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>(0, 82)\\t0.06096506732369721\\n  (0, 139)\\t0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>(0, 971)\\t0.4767427276757264\\n  (0, 515)\\t0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0      (0, 83)\\t0.009490899976104767\\n  (0, 231)\\t0...\n",
       "1      (0, 347)\\t0.0717112251874176\\n  (0, 62)\\t0.0...\n",
       "2      (0, 1001)\\t0.4714018667072575\\n  (0, 424)\\t0...\n",
       "3      (0, 149)\\t0.12681261954079942\\n  (0, 21)\\t0....\n",
       "4      (0, 627)\\t0.12736300042116153\\n  (0, 62)\\t0....\n",
       "..                                                 ...\n",
       "432    (0, 136)\\t0.4251433515438467\\n  (0, 958)\\t0....\n",
       "433    (0, 186)\\t0.14346710639962854\\n  (0, 597)\\t0...\n",
       "434    (0, 62)\\t0.03098285517981942\\n  (0, 58)\\t0.0...\n",
       "435    (0, 82)\\t0.06096506732369721\\n  (0, 139)\\t0....\n",
       "436    (0, 971)\\t0.4767427276757264\\n  (0, 515)\\t0....\n",
       "\n",
       "[437 rows x 1 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f987c7e9-d325-4bef-8615-e3ec3b4580f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category Types\n",
       "infrastructure     411\n",
       "community          360\n",
       "zoning              54\n",
       "public safety       34\n",
       "environmental       23\n",
       "safety              20\n",
       "governance          12\n",
       "housing              9\n",
       "finance              2\n",
       "human resources      1\n",
       "education            1\n",
       "administration       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Category Types'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a332da-bcd5-4f2e-b9d9-46a29cffbfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4922acd3-2b84-4d92-bbf9-bc840b5a634f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13302a6f-61e5-4213-9709-9190e644c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1cac6-aaa9-4a65-a550-a111e40bf329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730479e-03a4-49f2-b4e0-14b4a79a6eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0563d8-68c4-4893-8aed-4cf5d0c92090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bb007-8d19-4d24-b532-3b1bb0d31f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1aa62-d6e3-495c-a271-9286ffcb7b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "504f51f1-f476-4e45-8834-7ee3000dcc68",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ce739b4-517a-41b2-82cf-bba737523ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0, 10, 8, 7, 7, 1, 9, 9, 9, 4, 7, 1, 7, 0, 4, 7, 5, 7, 5, 0, 7, 8, 2, 4, 9, 2, 8, 12, 10, 2, 2, 0, 5, 8, 9, 2, 2, 4, 7, 8, 1, 5, 11, 8, 2, 1, 1, 11, 5, 3, 10, 9, 10, 5, 7, 8, 4, 5, 3, 10, 11, 12, 8, 7, 11, 3, 8, 1, 9, 4, 7, 5, 1, 5, 9, 2, 4, 1, 10, 5, 11, 0, 8, 6, 5, 0, 11, 7, 3, 6, 4, 10, 3, 2, 10, 8, 11, 7, 9, 2, 6, 7, 9, 8, 1, 6, 2, 12, 3, 6, 2, 9, 7, 0, 8, 0, 10, 4, 9, 4, 0, 0, 12, 12, 6, 0, 3, 8, 4, 7, 0, 8, 9, 10, 9, 3, 6, 9, 4, 5, 1, 7, 8, 4, 9, 8, 5, 10, 8, 7, 4, 3, 0, 5, 2, 12, 9, 5, 0, 5, 3, 10, 0, 0, 11, 7, 8, 3, 10, 1, 5, 3, 3, 1, 12, 12, 4, 10, 12, 7, 11, 12, 11, 8, 6, 1, 7, 12, 7, 9, 6, 2, 10, 4, 7, 0, 7, 11, 11, 9, 7, 3, 0, 7, 12, 11, 8, 6, 5, 0, 12, 5, 8, 12, 8, 12, 1, 4, 4, 10, 6, 2, 1, 3, 10, 7, 6, 12, 7, 10, 6, 5, 0, 7, 6, 8, 1, 0, 6, 0, 3, 11, 8, 1, 9, 0, 5, 2, 1, 11, 12, 12, 6, 9, 9, 3, 9, 2, 9, 7, 3, 2, 3, 6, 8, 9, 4, 11, 7, 1, 10, 10, 8, 3, 10, 1, 0, 7, 4, 7, 12, 12, 6, 1, 3, 4, 2, 1, 2, 12, 2, 3, 8, 7, 2, 10, 0, 8, 8, 12, 8, 5, 12, 1, 7, 9, 9, 9, 11, 3, 0, 8, 0, 9, 9, 6, 5, 3, 4, 10, 9, 11, 0, 9, 10, 9, 7, 7, 4, 10, 7, 7, 6, 0, 10, 4, 11, 12, 8, 7, 6, 7, 10, 9, 12, 10, 2, 4, 9, 6, 4, 3, 9, 11, 8, 8, 10, 5, 0, 1, 10, 0, 5, 3, 4, 3, 12, 11, 4, 7, 6, 2, 6, 4, 7, 5, 10, 8, 4, 10, 11, 12, 8, 4, 4, 2, 8, 10, 12, 2, 11, 0, 4, 0, 11, 8, 4, 1, 3, 2, 4, 9, 5, 12, 7, 8, 8, 10, 2, 9, 0, 1, 5, 10, 12, 12, 3, 2, 4, 12, 3, 5, 9, 6, 2, 10, 7, 10, 12, 3, 0, 10, 8, 10, 3, 0, 0]\n",
      "Actual labels: [ 0 10  5  7  7  1  9  9  9  4  7  1  7  0  4  7  5  7  5  8  7  1  2  4\n",
      "  9  8  1 12 10  2  2  0  5  8  9  2  2  4  7  8  8  1 11  5  2  1  1 11\n",
      "  5  3 10  9 10  5  7  8  4  5  3 10 11 12  8  7 11  3  5  1  9  8  7  5\n",
      "  1  5  9  2  4  1 11  8 11  0  1  6  5  0  5  7  3  6  4 10  3  2  8  6\n",
      "  5  7  9  2  6  7 11 11  1  6  2 12  3  6  2  9  7  0  8  0 10  4  9  4\n",
      "  0  0 12 12  6  0  3  5  4  7  0  1  9 10  9  3  6  8  4  5  1  7  8  4\n",
      "  9  6  5 10  5  7  4  3  0  5  2 12  9  5  0  5  3 10  0  5 11  7  1  3\n",
      " 10  1  5  3  3  1 12 12  4 10 12  7 11 12 11  5  6 11  7 12  7  9  6  2\n",
      " 10  4  7  0  7 11 11  9  7  3  0  7 12 11  6  6  5  0 12  5  8 12  5 12\n",
      "  1  4  4 10  6  2  1  3 10  7  6 12  7 10  6  5  0  7  6  1  1  0  6  0\n",
      "  3  5  5 11  9  0  5  2 11 11 12 12  6  9  9  3  9  2  9  7  3  2  8  6\n",
      "  5  9  8 11  7 11 10 10  5  3 10  1  0  7  4  7 12 12  6  1  3  4  2  1\n",
      "  2 12  2  3  8  7  2 10  0  8  8 12  5  5 12  1  7  9  9  9 11  5  0  8\n",
      "  0  9  9  6  5  5  4 10  9 11  0  9 10  9  7  7  4 10  7  7  6  0  6  8\n",
      " 11 11  1  7  6  7 10  9 12  5  2  4  9  6  4  3  9 11  6  1 10  5  0  1\n",
      " 10  0  5  3  4  3 12 11  4  7  8  2  6  4  7  8 10  8  4 10  5 12  5  4\n",
      "  4  2  8 10 12  2 11  0  4  0 11  5  4  1  3  2  4  9  5  8  7  5  1 10\n",
      "  2  9  0  1  5 10 12 12  3  2  8 12  8  5  9  6  2 10  7 10 12  3  0  1\n",
      "  8 10  3  0  8]\n",
      "Accuracy: 0.8581235697940504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "k = 2  # Number of neighbors\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='cosine')\n",
    "nn.fit(X_train)  # NearestNeighbors requires dense input if using cosine\n",
    "\n",
    "# Finding the k-nearest neighbors for each point in the test set\n",
    "distances, indices = nn.kneighbors(X_test)\n",
    "\n",
    "# Voting logic to classify based on the nearest neighbors\n",
    "y_pred = []\n",
    "for index_array in indices:\n",
    "    neighbor_labels = [y_train[idx] for idx in index_array]\n",
    "    # Get the most common class label among the nearest neighbors\n",
    "    most_common = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    y_pred.append(most_common)\n",
    "\n",
    "# Compare the predictions with the actual labels\n",
    "print(\"Predicted labels:\", y_pred)\n",
    "print(\"Actual labels:\", y_test)\n",
    "#calculate accuracy\n",
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if (y_pred[i] == y_test[i]):\n",
    "        count += 1\n",
    "print (\"Accuracy:\", count / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e889c-f82d-461d-96b2-9c15a5e09696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72400f-b6ed-4ce9-ae61-efa040910a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d576324-5606-443d-bb35-f61df06f7d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60c035cf-0fe2-4c2e-909f-8bb918675838",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7a35044-6115-4692-9135-2c8d91396b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 3s - 463ms/step - accuracy: 0.1483 - loss: 0.1082 - val_accuracy: 0.1824 - val_loss: 0.1036\n",
      "Epoch 2/5\n",
      "6/6 - 0s - 47ms/step - accuracy: 0.1628 - loss: 0.0734 - val_accuracy: 0.1824 - val_loss: 0.0466\n",
      "Epoch 3/5\n",
      "6/6 - 0s - 46ms/step - accuracy: 0.1628 - loss: 0.0441 - val_accuracy: 0.1824 - val_loss: 0.0416\n",
      "Epoch 4/5\n",
      "6/6 - 0s - 49ms/step - accuracy: 0.1628 - loss: 0.0414 - val_accuracy: 0.1824 - val_loss: 0.0409\n",
      "Epoch 5/5\n",
      "6/6 - 0s - 45ms/step - accuracy: 0.1628 - loss: 0.0409 - val_accuracy: 0.1824 - val_loss: 0.0407\n",
      "Accuracy: 0.18\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
    "tokenizer.fit_on_texts(base_df['Description'])\n",
    "X = tokenizer.texts_to_sequences(base_df['Description'])\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(base_df['Class'])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='CategoricalHinge', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac58201-dc07-47c8-aed9-d91990d87123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e15ea-23b3-4a86-94d0-4f07dedaeac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a6e88-a66f-46df-86dc-99b6eff40790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ae11b-5c30-495f-8a37-d37c360f6779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900ca4d-fa2f-446d-aa46-5afeb9060d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62eb19-89e9-47cf-9f1f-6e5e136997a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f42c47-06ac-4666-8fb7-3758f06fb1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c67106-b19f-4c21-8098-8a87217750a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9798696-98ab-4101-b94a-8ee48b8abcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64cefe-cca2-4796-8e02-c2be6ec0ac94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d404cc24-8c1e-4530-9c13-da38ae00c21e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Word2Vec model -- feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c85b9b2-b0b0-4553-aeb6-ced9db53546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce23f873-faf2-44ee-a76c-cb5862f1036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(base_df, test_size=0.2, random_state=42)\n",
    "model_w2v = Word2Vec(sentences=train['Description'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "import numpy as np\n",
    "\n",
    "def document_vector(doc):\n",
    "    doc = [word for word in doc if word in model_w2v.wv.key_to_index]\n",
    "    return np.mean(model_w2v.wv[doc], axis=0) if doc else np.zeros(model_w2v.vector_size)\n",
    "\n",
    "train_vectors = np.array([document_vector(doc) for doc in train['Description']])\n",
    "test_vectors = np.array([document_vector(doc) for doc in test['Description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39eea0f9-90ea-43ec-893e-5733d136230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_smote, train_labels_smote = smote.fit_resample(train_vectors, train['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81d77dc3-a14e-4296-a699-66460341afcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(train_vectors_smote, train_labels_smote)\n",
    "\n",
    "predictions = logreg.predict(test_vectors)\n",
    "\n",
    "accuracy = accuracy_score(test['Class'], predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb904c-8bf0-4611-a20c-18e83e9b3c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc166c4-c0ab-4d38-84d2-e961c812ba50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000c019-ac11-4639-a57c-85001730a4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95c96e-6cff-4768-b663-622c5ff7867a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd20414-1319-4b3e-97ce-eaeda54d1f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f005a89-d8cd-4429-933f-0867327fa59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa72711-b159-4174-9a77-5914c9f104df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56600d9e-233f-40c8-ad05-652cb9f25f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabd490-2694-452d-ae41-063f74696e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6bb14d-141e-4168-a451-ae9aab5db2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733dd76f-34d2-45ae-88b5-af23d712a4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de074cb-73a7-4812-9c22-9690a842bd78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17574f-400b-4f45-b7c7-48a4f3cdd7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc913cf0-90c5-4761-a97a-31a45e3214bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb786e72-48fe-42d5-a5df-ed2dba31e79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6a7f6d-8945-4cba-80b3-7c380f2a3c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
